{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "## \"Just ahead of time\" compilation\n",
    "\n",
    "* Julia **specializes on the types of function arguments** and \n",
    "* compiles efficient machine code **when a function is called for the first time** (with these input argument types).\n",
    "\n",
    "If the same function is called again with the same input argument types, the already existing machine code is reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(x,y) = 2x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.2, 3.4, 5.6] # Vector{Float64}\n",
    "y = [0.4, 0.7, 0.9] # Vector{Float64}\n",
    "\n",
    "@time func(x,y);\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First call:** compilation + running the code\n",
    "\n",
    "**Second call:** running the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one of the input types changes, Julia compiles a new specialization of the function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y); # Vector{Int64}, Vector{Float64}\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two efficient native codes in the cache: one for all `Vector{Float64}` inputs and another one for `Vector{Int64}` as the first and `Vector{Float64}` as the second argument type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(Base.specializations(only(methods(func))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation pipeline\n",
    "\n",
    "<p><br><img src=\"../images/Julia_compilation_pipeline.svg\" width=\"512\"/></p>\n",
    "\n",
    "* **AST**: abstract syntax tree\n",
    "* **IR**: intermediate representation\n",
    "\n",
    "More about Julia compilation, see [Bezanson J et al (2018) Julia: dynamism and performance reconciled by design. Proc ACM Program Lang.](https://doi.org/10.1145/3276490)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What makes Julia fast?\n",
    "\n",
    "**Specialization** → (Successful) **Type inference** → **Compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introspection tools\n",
    "#### (*But I really want to see what happens!*)\n",
    "\n",
    "We can inspect the code at all transformation stages with a bunch of macros:\n",
    "\n",
    "<img src=\"../images/julia_introspection_macros.svg\" width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_lowered func(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the types of the input arguments, Julia has figured out all the intermediate types. This crucial process is known as **type inference** and its success is the basis for a good specialization (i.e. performant native code as a result). Moreover, the generic power function computing the cubic of `x` is replaced by specific floating-point multiplications (**static dispatch**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm debuginfo=:none func(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Code is Fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Julia, user code and user types can be just as fast as built-in or library code.**\n",
    "\n",
    "If you know what you're doing, you can typically match the performance of optimized C/Fortran code.\n",
    "\n",
    "In the following, we illustrate this with two basic examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User code: Summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(10^7); # some numbers to be summed up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What this does: compile simple C sum function into a shared library by piping C code into gcc\n",
    "\n",
    "c_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\";\n",
    "\n",
    "using Libdl\n",
    "Clib = tempname() * \".\" * Libdl.dlext\n",
    "\n",
    "open(`gcc -fPIC -O3 -march=native -xc -shared -o $Clib -`, \"w\") do f\n",
    "    print(f, c_code)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readily call the function `c_sum` in the shared library\n",
    "\n",
    "c_sum(X::Array{Float64}) = @ccall Clib.c_sum(length(X)::Csize_t, X::Ptr{Float64})::Float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum(x) ≈ sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function jl_sum(A)\n",
    "    s = zero(eltype(A)) # the correct zero type for A\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime c_sum($x) samples = 100 evals = 10;\n",
    "@btime jl_sum($x) samples = 100 evals = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User type: Diagonal matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple custom `DiagonalMatrix` type that can represent square diagonal matrices, i.e.\n",
    "\n",
    "$$ D = \\left( \\begin{matrix} x & 0 & 0 & 0 \\\\ 0 & y & 0 & 0 \\\\ 0 & 0 & z & 0 \\\\ 0 & 0 & 0 & \\ddots \\end{matrix} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct DiagonalMatrix{T} <: AbstractArray{T,2}\n",
    "    diag::Vector{T}\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integrate our `DiagonalMatrix` into Julia's type hierarchy by making it a subtype of `AbstractMatrix` to indicate **matrix-like behavior**. To actually make it behave like a matrix (a two-dimensional array) we implement at least (parts of) the [`AbstractArray` interface](https://docs.julialang.org/en/v1/manual/interfaces/#man-interface-array-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement AbstractArray interface\n",
    "function Base.getindex(D::DiagonalMatrix, i::Int, j::Int)\n",
    "    if i == j\n",
    "        return D.diag[i]\n",
    "    else\n",
    "        return zero(eltype(D))\n",
    "    end\n",
    "end\n",
    "\n",
    "function Base.setindex!(D::DiagonalMatrix, v, i::Int, j::Int)\n",
    "    if i == j\n",
    "        D.diag[i] = v\n",
    "    else\n",
    "        throw(ArgumentError(\"cannot set off-diagonal entry ($i, $j)\"))\n",
    "    end\n",
    "    return v\n",
    "end\n",
    "\n",
    "Base.size(D::DiagonalMatrix) = (length(D.diag), length(D.diag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DiagonalMatrix([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how it's automagically pretty printed (despite the fact that we never defined any special printing)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's not it. Because of duck typing, all kinds of different functions now \"just work\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D + D # addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D * D # multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv(D) # inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "eigen(D) # eigensolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, so far, these operations have suboptimal performance because they don't utilize the special structure inherent to our `DiagonalMatrix` but fall back to generic implementations. Let's implement an efficient addition for our diagonal matrix type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base: +\n",
    "\n",
    "+(Da::DiagonalMatrix, Db::DiagonalMatrix) = DiagonalMatrix(Da.diag + Db.diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare our very rudamentary `DiagonalMatrix` against the standard `Diagonal` type that ships in the `LinearAlgebra` standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using LinearAlgebra\n",
    "\n",
    "x = rand(1000);\n",
    "Djl = Diagonal(x)\n",
    "D = DiagonalMatrix(x)\n",
    "\n",
    "@btime $Djl + $Djl;\n",
    "@btime $D + $D;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
